{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4UnWeEbbhaC"
      },
      "source": [
        "# Define model and import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6WR2TTAwamN-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import optim, nn, utils, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Djs-6wbamOD"
      },
      "outputs": [],
      "source": [
        "# Defining our model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        out = self.fc(out[:, -1, :])\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObnVOnalamOE",
        "outputId": "b951aa51-0560-435f-c8a3-521902006f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMeD49LjamOL",
        "outputId": "e4e55a6a-fe02-4e77-ff1d-478b7a034967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available. But should work fine on CPU too.\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print('device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnMKDmKWamOF"
      },
      "source": [
        "## If you're training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wqGdqFzamOI"
      },
      "outputs": [],
      "source": [
        "# train and validation data\n",
        "!unzip -q /content/drive/MyDrive/ybigta/2023-2/win_prediction_model/initial.zip -d /content/initial\n",
        "\n",
        "# Open data_label, contains keypoints numpy array names and labels\n",
        "data_label = pd.read_csv(\"/content/initial/data_label.csv\", index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWaKYPk4amOJ"
      },
      "outputs": [],
      "source": [
        "# custom defined dataset for our data format\n",
        "class KeypointsDataset(Dataset):\n",
        "    def __init__(self, array_paths, labels, num_input):\n",
        "        \"\"\"\n",
        "        Generates a custom numpy dataset\n",
        "\n",
        "        Args:\n",
        "            array_paths (list): list of numpy array inputs\n",
        "            labels (list): list of labels\n",
        "            num_input (int) : number of inputs to enter\n",
        "        \"\"\"\n",
        "        self.array_paths = array_paths\n",
        "        self.labels = labels\n",
        "        self.num_input = num_input\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns length of entire dataset\n",
        "        \"\"\"\n",
        "        return len(self.array_paths)\n",
        "\n",
        "    def __getitem__(self, idx, ):\n",
        "        \"\"\"\n",
        "        Gets the sample that corresponds to the sample id (idx)\n",
        "\n",
        "        Args:\n",
        "            idx (int): sample index\n",
        "\n",
        "        Returns:\n",
        "            keypoints (torch.Tensor): keypoints input tensor\n",
        "            label (torch.Tensor): winning label tensor\n",
        "        \"\"\"\n",
        "        keypoints_path = \"/content/initial/data/\"\n",
        "        # load and turn numpy arrays into torch tensors\n",
        "        keypoints = np.load(f\"{keypoints_path}{self.array_paths[idx]}.npy\")\n",
        "        keypoints = keypoints[:,-self.num_input:]\n",
        "        keypoints = torch.tensor(keypoints, dtype = torch.float32)\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return keypoints, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_LGXr03amOJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_array, val_array = train_test_split(data_label, test_size = 0.1, random_state = 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8PqcBB_amOK"
      },
      "outputs": [],
      "source": [
        "# Initialise the dataset and dataloader\n",
        "num_in = 100\n",
        "train_data = KeypointsDataset(\n",
        "    array_paths = train_array['modified_json_filename'].reset_index(drop = True),\n",
        "    labels = train_array['label'].reset_index(drop=True),\n",
        "    num_input = num_in\n",
        "    )\n",
        "val_data = KeypointsDataset(\n",
        "    array_paths = val_array['modified_json_filename'].reset_index(drop= True),\n",
        "    labels = val_array['label'].reset_index(drop= True),\n",
        "    num_input = num_in\n",
        "    )\n",
        "train_loader = DataLoader(train_data)\n",
        "val_loader = DataLoader(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGgmuq4TamOL"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if i %  51 == 0:\n",
        "            loss, current = loss.item(), (i + 1) * len(inputs)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloader):\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          test_loss += loss_fn(outputs, labels).item()\n",
        "          correct += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucPlJ2lOamOM"
      },
      "outputs": [],
      "source": [
        "# Setting up the model and initiating the train & validation loops\n",
        "model = LSTMModel(input_size=num_in, hidden_size=10, num_layers=1, num_classes=2).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay = 0.1)\n",
        "\n",
        "num_epochs = 100\n",
        "for t in range(num_epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    test_loop(val_loader, model, criterion)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2btF-4ramOM"
      },
      "outputs": [],
      "source": [
        "# If you're continuing to train from a pre-trained version:\n",
        "pretrained_path = \"/content/drive/MyDrive/ybigta/2023-2/win_prediction_model/winpred_model_sd\"\n",
        "model = LSTMModel(input_size=num_in, hidden_size=10, num_layers=1, num_classes=2).to(device)\n",
        "model.load_state_dict(torch.load(pretrained_path, map_location= torch.device(\"cpu\")), strict = False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay = 0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "for t in range(num_epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, criterion, optimizer)\n",
        "    test_loop(val_loader, model, criterion)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEEN0sqEamOM"
      },
      "source": [
        "## If you're doing a test:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0vIiVDTamOM"
      },
      "source": [
        "### Test Dataset Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CMutqD5jbOuR"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/ybigta/2023-2/win_prediction_model/test_keypoints.zip -d /content/test_keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oDlhxtoEamOM"
      },
      "outputs": [],
      "source": [
        "PATH_TO_NUMPY_ARRAY_FOLDER = \"/content/test_keypoints/test_keypoints\"\n",
        "PATH_TO_NUMPY_ARRAY_FILENAMES_AND_LABELS = \"/content/test_keypoints/test_data_label.csv\"\n",
        "PATH_TO_PRETRAINED_MODEL_STATE_DICT = \"/content/drive/MyDrive/ybigta/2023-2/win_prediction_model/winpred_model_sd\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8LYEa0boamON"
      },
      "outputs": [],
      "source": [
        "class KeypointsDataset(Dataset):\n",
        "    def __init__(self, array_paths, labels, num_input):\n",
        "        \"\"\"\n",
        "        Generates a custom numpy dataset\n",
        "\n",
        "        Args:\n",
        "            array_paths (list): list of numpy array inputs\n",
        "            labels (list): list of labels\n",
        "            num_input (int) : number of inputs to enter\n",
        "        \"\"\"\n",
        "        self.array_paths = array_paths\n",
        "        self.labels = labels\n",
        "        self.num_input = num_input\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns length of entire dataset\n",
        "        \"\"\"\n",
        "        return len(self.array_paths)\n",
        "\n",
        "    def __getitem__(self, idx, ):\n",
        "        \"\"\"\n",
        "        Gets the sample that corresponds to the sample id (idx)\n",
        "\n",
        "        Args:\n",
        "            idx (int): sample index\n",
        "\n",
        "        Returns:\n",
        "            keypoints (torch.Tensor): keypoints input tensor\n",
        "            label (torch.Tensor): winning label tensor\n",
        "        \"\"\"\n",
        "        keypoints_path = PATH_TO_NUMPY_ARRAY_FOLDER\n",
        "        # Turn numpy arrays into torch tensors\n",
        "        keypoints = np.load(f\"{keypoints_path}{self.array_paths[idx]}.npy\")\n",
        "        keypoints = keypoints[:,-self.num_input:]\n",
        "        keypoints = torch.tensor(keypoints, dtype = torch.float32)\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return keypoints, label\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloader):\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          test_loss += loss_fn(outputs, labels).item()\n",
        "          correct += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "test_array = pd.read_csv(PATH_TO_NUMPY_ARRAY_FILENAMES_AND_LABELS)\n",
        "num_in = 100 # DO NOT ALTER\n",
        "test_data = KeypointsDataset(\n",
        "    array_paths = test_array['modified_json_filename'].reset_index(drop= True),\n",
        "    labels = test_array['label'].reset_index(drop= True),\n",
        "    num_input = num_in\n",
        "    )\n",
        "test_loader = DataLoader(test_data)\n",
        "pretrained_path = PATH_TO_PRETRAINED_MODEL_STATE_DICT\n",
        "model = LSTMModel(input_size=num_in, hidden_size=10, num_layers=1, num_classes=2).to(device)\n",
        "model.load_state_dict(torch.load(pretrained_path, map_location= torch.device(\"cuda\")), strict = False)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWqj1LYxamON",
        "outputId": "3815ccb7-cf47-4c79-f00d-480111c4b887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 37.5%, Avg loss: 0.753404 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run this after setting all the paths, and the above cell (loading the model)\n",
        "test_loop(test_loader, model, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_8c3hz0amON"
      },
      "source": [
        "### Individual File Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBYlEXx3bVRE",
        "outputId": "21262a94-ccf5-4028-b06d-14ea30e84a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace /content/test_keypoints/31_person.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!unzip -q /content/drive/MyDrive/ybigta/2023-2/win_prediction_model/test_keypoints.zip -d /content/test_keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xTUscQotamON"
      },
      "outputs": [],
      "source": [
        "PATH_TO_NUMPY_ARRAY = \"/content/test_keypoints/31_person.npy\"\n",
        "PATH_TO_PRETRAINED_MODEL_STATE_DICT = \"/content/drive/MyDrive/ybigta/2023-2/win_prediction_model/winpred_model_sd\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aghEJ86pamON",
        "outputId": "851b8af8-dffe-4e7d-f06e-e9e98fa02397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The result is:0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0, device='cuda:0', dtype=torch.int32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numpy_data = np.load(PATH_TO_NUMPY_ARRAY)\n",
        "\n",
        "pretrained_path = PATH_TO_PRETRAINED_MODEL_STATE_DICT\n",
        "model = LSTMModel(input_size=num_in, hidden_size=10, num_layers=1, num_classes=2).to(device)\n",
        "# If there's no GPU, change from device(\"cuda\") to device(\"cpu\")\n",
        "model.load_state_dict(torch.load(pretrained_path, map_location= torch.device(\"cuda\")), strict = False)\n",
        "\n",
        "def test(numpy_data_raw, model):\n",
        "    data = torch.tensor(numpy_data_raw[:, -100:], dtype = torch.float32)\n",
        "    data = data[None, :]\n",
        "    data = data.to(device)\n",
        "    model.eval()\n",
        "    outputs = model(data)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    predicted_int = predicted.type(torch.int)[0]\n",
        "    print(f\"The result is:{predicted_int:d}\")\n",
        "    return predicted_int\n",
        "test(numpy_data, model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GnMKDmKWamOF",
        "SEEN0sqEamOM",
        "w0vIiVDTamOM",
        "O_8c3hz0amON"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
